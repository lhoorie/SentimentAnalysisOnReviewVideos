
\def \Subject {تحلیل احساسات روی ویدئوهای نقد فیلم‌‌های سینمایی}
\def \Course {درس پردازش زبان‌های طبیعی}
\def \Author {حوریه سبزواری}
\def \Report {گزارش فاز دوم}
\def \StudentNumber {98412004}

\begin{center}
\vspace{.4cm}
{\bf {\huge \Subject}}\\
{\bf \Large \Course}
\vspace{.2cm}
\end{center}
{\bf \Author }  \\
{\bf شماره دانشجویی:\ \StudentNumber}
\hspace{\fill} 
{\Large \Report} \\
\hrule
\vspace{0.8cm}

\clearpage

%\huge{\Subject}\\[1.5 cm]
%\chapterauthor{\Author~ : \StudentNumber}
\par
موضوع پروژه تسک \texttt{sentiment analysis} روی ویدیو‌های نقد و بررسی فیلم‌های سینمایی است. داده‌ها از منتقدهای مشغول به فعالیت در پلتفرم یوتیوب جمع‌آوری می‌شود. در انتها برای هر داده‌ی ورودی مشخص می‌گردد که نظر کلی ویدیو راجع به آن فیلم سینمایی خوب، متوسط یا بد بوده است.\\ \\
لینک \lr{Repository}: \href{https://github.com/lhoorie/SentimentAnalysisOnReviewVideos}{https://github.com/lhoorie/SentimentAnalysisOnReviewVideos}

\section{\lr{Word2Vec}}
\begin{itemize}
\item ابتدا مدل \lr{Word2Vec} از کتابخانۀ \lr{gensim} را برای هر 3 برچسب آموزش می‌دهیم.
\item سپس مدل‌های نهایی را با نام \lr{<label>.word2vec.bin} در پوشۀ \lr{models} ذخیره می‌کنیم.
\item حال کلمات مشترک بین 3 برچسب را پیدا کرده و بردارهای آن‌ها را با استفاده از مقایسۀ شباهت کسینوسی میزان شباهت و تفاوت کلمات را می‌یابیم.
\item در انتها نیز یک مدل \lr{word2vec} روی تمام داده آموزش می‌دهیم.

کلمات با بردارهای مشابه و متفاوت در خروجی چاپ شده در کد موجود در \lr{notebook} قسمت \lr{Word2Vec} قابل مشاهده است. تفاوت احتمالاً به این دلیل است که \lr{Word2Vec}جاسازی های کلمه را بر اساس زمینه‌ای که کلمه در آن ظاهر می شود، یاد می‌گیرد. بردارهای کلمه برای به تصویر کشیدن معنا و روابط بین کلمات در زمینۀ خاص داده های آموزشی آموزش داده شده‌اند.
هنگام آموزش \lr{Word2Vec}الگوریتم از یک رویکرد پنجرۀ کشویی برای گرفتن متن هر کلمه استفاده می‌کند. احتمال وقوع یک کلمه را بر اساس کلمات همسایه آن پیش‌بینی می کند. در نتیجه، بردارهای کلمه آموخته شده بسته به کلمات اطرافی که کلمه در آن ظاهر می‌شود، می‌تواند متفاوت باشد.
\end{itemize}

\section{\lr{Tokenizer}}
در این بخش ابتدا از \lr{tokenizer} گفته شده در صورت سوال استفاده کردم و خروجی درستی نمی‌داد. سپس از \lr{tokenizer BERT} استفاده کردم و تنظیمات مربوطه و خود مدل را در پوشۀ \lr{models} ذخیره کردم.
BERT متن را با در نظر گرفتن قوانین خاص زبان به کلمات جداگانه تقسیم می کند. به عنوان مثال، "running" را به "run" و "ning" تقسیم می کند تا پردازش زیر کلمه را فعال کند.

BERT از تکنیکی به نام WordPiece استفاده می کند. این بیشتر کلمات را به زیرکلمه ها یا دنباله های کاراکتر تقسیم می کند تا کلمات خارج از واژگان (OOV) را مدیریت کند و تغییرات مشخص شود.

BERT نشانه‌های خاصی را برای علامت‌گذاری شروع و پایان یک دنباله، جملات جداسازی و نشان دادن padding اضافه می‌کند. این نشانه ها عبارتند از [CLS] (طبقه بندی)، [SEP] (جداکننده) و [PAD]

 یک ماسک \lr{attention} نیز ایجاد می‌شود تا نشان دهد کدام نشانه‌ها بخشی از دنباله ورودی هستند و کدام نشانه‌های padding هستند. به مدیریت توالی های ورودی با طول متغیر کمک می کند.

\clearpage
 \section{\lr{Language Model}}
 در این بخش از مدل از پیش آموختۀ \lr{OpenAI} بنام \lr{GP2} استفاده کردم. مدل را بر روی داده‌های هر دسته \lr{finetune} کرده و در پوشۀ \lr{models} ذخیره کردم. کیفیت جملات تولیدشده پس از یکی دو خط بسیار افت می‌کرد و یا جملات تکراری تولید می‌کرد. این مورد می‌تواند ناشی از این باشد که 
 GPT-2 متن را به صورت متوالی پردازش می کند و بر زمینه ارائه شده در توکن های قبلی متکی است. با این حال، ممکن است همیشه وابستگی های دور را شامل نشود یا تفاوت های ظریف بافتی پیچیده را درک نکند. در نتیجه، گاهی اوقات می تواند متنی تولید کند که فاقد انسجام باشد یا ناسازگاری های معنایی را نشان دهد.

 \section{\lr{Feature Engineering}}
 ویژگی‌های گفته‌شده در در صورت سوال در کد موجود پیاده‌سازی شده اما ران کردن این بخش باعث پر شدن رم \lr{Google Collab} شد و متاسفانه نتیجه‌ای حاصل نگردید.

 \section{\lr{Model Architecture}}
 در این قسمت از معماری \lr{BERT} استفاده شده است، دقت و \lr{loss} و خود مدل در پوشۀ مربوطه ذخیره شده‌اند.
 دقت حدودا 50 درصد بدست آمد که به نظر ناشی از طول جملات بالا و جمله‌بندی نبودن متن است. 

 \section{\lr{Data Augmentation}}
 با استفاده از \lr{API ChatGPT} و \lr{propmt} های داده‌شده اقدام به داده‌افزایی کردم.
 داده‌های تولیدشده از نظر طول متن بسیار کوتاه‌تر از داده‌های اصلی بودند. اما از نظر محتوا نسبت به برچسب داده‌شده دارای کیفیت مطلوبی داشتند.\\
 \lr{Prompt for label 0 : prompt = "Generate a transcript review of a bad movie:"
}\\
\lr{Prompt for label 1 : prompt = "Generate a transcript review of a so-so and neutral movie:"
}\\
\lr{Prompt for label 2 : prompt = "Generate a transcript review of a good movie:"
}\\

نمونه داده‌های تولیدشده در کد قابل مشاهده می‌باشد.